{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7PbTeoDgdL7"
      },
      "source": [
        "# **Reinforcement Learning using DQN for Atari**\n",
        "### *Ranya El-Hwigi 18227449*\n",
        "### *Nutsa Chichilidze 18131956*\n",
        "\n",
        "Code runs to completion, but takes a very long time. \n",
        "Some implementation elements borrowed from: \n",
        "https://github.com/Hauf3n/DDQN-Atari-PyTorch/blob/master/DQN_Atari.ipynb and the official PyTorch documentation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing packages necessary to train and display our network\n",
        "!pip3 install scipy==1.1.0\n",
        "!sudo apt-get install xvfb\n",
        "!pip3 install xvfbwrapper\n",
        "!apt update && apt install xvfb && pip3 install pyvirtualdisplay && pip install pyvirtualdisplay\n",
        "!apt-get install x11-utils > /dev/null 2>&1 \n",
        "!pip3 install pyglet > /dev/null 2>&1 \n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip3 install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://www.atarimania.com/roms/Roms.rar','Roms.rar')\n",
        "\n",
        "# importing the Atari ROMS\n",
        "!pip install unrar\n",
        "!unrar x Roms.rar\n",
        "!mkdir rars\n",
        "!mv HC\\ ROMS.zip   rars\n",
        "!mv ROMS.zip  rars\n",
        "!python -m atari_py.import_roms rars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoBs0s5y0H6L",
        "outputId": "94c2dd40-d2ec-424e-8401-0cae09a5c67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 78 not upgraded.\n",
            "Requirement already satisfied: xvfbwrapper in /usr/local/lib/python3.7/dist-packages (0.2.9)\n",
            "Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "78 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 78 not upgraded.\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: unrar in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from Roms.rar\n",
            "\n",
            "Extracting  HC ROMS.zip                                                  \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  ROMS.zip                                                     \b\b\b\b 74%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n",
            "mkdir: cannot create directory ‘rars’: File exists\n",
            "copying adventure.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Adventure (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/adventure.bin\n",
            "copying air_raid.bin from HC ROMS/BY ALPHABET (PAL)/A-G/Air Raid (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/air_raid.bin\n",
            "copying alien.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Alien.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/alien.bin\n",
            "copying crazy_climber.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Crazy Climber.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/crazy_climber.bin\n",
            "copying elevator_action.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Elevator Action (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/elevator_action.bin\n",
            "copying gravitar.bin from HC ROMS/BY ALPHABET (PAL)/A-G/REMAINING NTSC ORIGINALS/Gravitar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gravitar.bin\n",
            "copying keystone_kapers.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Keystone Kapers (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/keystone_kapers.bin\n",
            "copying king_kong.bin from HC ROMS/BY ALPHABET (PAL)/H-R/King Kong (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/king_kong.bin\n",
            "copying laser_gates.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Laser Gates (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/laser_gates.bin\n",
            "copying mr_do.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Mr. Do! (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/mr_do.bin\n",
            "copying pacman.bin from HC ROMS/BY ALPHABET (PAL)/H-R/Pac-Man (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pacman.bin\n",
            "copying jamesbond.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/James Bond 007.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/jamesbond.bin\n",
            "copying koolaid.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Kool-Aid Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/koolaid.bin\n",
            "copying krull.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Krull.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/krull.bin\n",
            "copying montezuma_revenge.bin from HC ROMS/BY ALPHABET (PAL)/H-R/REMAINING NTSC ORIGINALS/Montezuma's Revenge - Featuring Panama Joe.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/montezuma_revenge.bin\n",
            "copying star_gunner.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Stargunner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/star_gunner.bin\n",
            "copying time_pilot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Time Pilot.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/time_pilot.bin\n",
            "copying up_n_down.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/REMAINING NTSC ORIGINALS/Up 'n Down.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/up_n_down.bin\n",
            "copying sir_lancelot.bin from HC ROMS/BY ALPHABET (PAL)/S-Z/Sir Lancelot (PAL).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/sir_lancelot.bin\n",
            "copying amidar.bin from HC ROMS/BY ALPHABET/A-G/Amidar.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/amidar.bin\n",
            "copying asteroids.bin from HC ROMS/BY ALPHABET/A-G/Asteroids [no copyright].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asteroids.bin\n",
            "copying atlantis.bin from HC ROMS/BY ALPHABET/A-G/Atlantis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/atlantis.bin\n",
            "copying bank_heist.bin from HC ROMS/BY ALPHABET/A-G/Bank Heist.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bank_heist.bin\n",
            "copying battle_zone.bin from HC ROMS/BY ALPHABET/A-G/Battlezone.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/battle_zone.bin\n",
            "copying beam_rider.bin from HC ROMS/BY ALPHABET/A-G/Beamrider.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/beam_rider.bin\n",
            "copying berzerk.bin from HC ROMS/BY ALPHABET/A-G/Berzerk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/berzerk.bin\n",
            "copying bowling.bin from HC ROMS/BY ALPHABET/A-G/Bowling.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/bowling.bin\n",
            "copying boxing.bin from HC ROMS/BY ALPHABET/A-G/Boxing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/boxing.bin\n",
            "copying breakout.bin from HC ROMS/BY ALPHABET/A-G/Breakout - Breakaway IV.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/breakout.bin\n",
            "copying carnival.bin from HC ROMS/BY ALPHABET/A-G/Carnival.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/carnival.bin\n",
            "copying centipede.bin from HC ROMS/BY ALPHABET/A-G/Centipede.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/centipede.bin\n",
            "copying chopper_command.bin from HC ROMS/BY ALPHABET/A-G/Chopper Command.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/chopper_command.bin\n",
            "copying defender.bin from HC ROMS/BY ALPHABET/A-G/Defender.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/defender.bin\n",
            "copying demon_attack.bin from HC ROMS/BY ALPHABET/A-G/Demon Attack.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/demon_attack.bin\n",
            "copying donkey_kong.bin from HC ROMS/BY ALPHABET/A-G/Donkey Kong.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/donkey_kong.bin\n",
            "copying double_dunk.bin from HC ROMS/BY ALPHABET/A-G/Double Dunk.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/double_dunk.bin\n",
            "copying enduro.bin from HC ROMS/BY ALPHABET/A-G/Enduro.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/enduro.bin\n",
            "copying fishing_derby.bin from HC ROMS/BY ALPHABET/A-G/Fishing Derby.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/fishing_derby.bin\n",
            "copying freeway.bin from HC ROMS/BY ALPHABET/A-G/Freeway.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/freeway.bin\n",
            "copying frogger.bin from HC ROMS/BY ALPHABET/A-G/Frogger.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frogger.bin\n",
            "copying frostbite.bin from HC ROMS/BY ALPHABET/A-G/Frostbite.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/frostbite.bin\n",
            "copying galaxian.bin from HC ROMS/BY ALPHABET/A-G/Galaxian.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/galaxian.bin\n",
            "copying gopher.bin from HC ROMS/BY ALPHABET/A-G/Gopher.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/gopher.bin\n",
            "copying hero.bin from HC ROMS/BY ALPHABET/H-R/H.E.R.O..bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/hero.bin\n",
            "copying ice_hockey.bin from HC ROMS/BY ALPHABET/H-R/Ice Hockey.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ice_hockey.bin\n",
            "copying journey_escape.bin from HC ROMS/BY ALPHABET/H-R/Journey Escape.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/journey_escape.bin\n",
            "copying kaboom.bin from HC ROMS/BY ALPHABET/H-R/Kaboom!.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kaboom.bin\n",
            "copying kangaroo.bin from HC ROMS/BY ALPHABET/H-R/Kangaroo.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kangaroo.bin\n",
            "copying kung_fu_master.bin from HC ROMS/BY ALPHABET/H-R/Kung-Fu Master.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/kung_fu_master.bin\n",
            "copying lost_luggage.bin from HC ROMS/BY ALPHABET/H-R/Lost Luggage [no opening scene].bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/lost_luggage.bin\n",
            "copying ms_pacman.bin from HC ROMS/BY ALPHABET/H-R/Ms. Pac-Man.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/ms_pacman.bin\n",
            "copying name_this_game.bin from HC ROMS/BY ALPHABET/H-R/Name This Game.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/name_this_game.bin\n",
            "copying phoenix.bin from HC ROMS/BY ALPHABET/H-R/Phoenix.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/phoenix.bin\n",
            "copying pitfall.bin from HC ROMS/BY ALPHABET/H-R/Pitfall! - Pitfall Harry's Jungle Adventure.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pitfall.bin\n",
            "copying pooyan.bin from HC ROMS/BY ALPHABET/H-R/Pooyan.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pooyan.bin\n",
            "copying private_eye.bin from HC ROMS/BY ALPHABET/H-R/Private Eye.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/private_eye.bin\n",
            "copying qbert.bin from HC ROMS/BY ALPHABET/H-R/Q-bert.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/qbert.bin\n",
            "copying riverraid.bin from HC ROMS/BY ALPHABET/H-R/River Raid.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/riverraid.bin\n",
            "copying road_runner.bin from patched version of HC ROMS/BY ALPHABET/H-R/Road Runner.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/road_runner.bin\n",
            "copying robotank.bin from HC ROMS/BY ALPHABET/H-R/Robot Tank.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/robotank.bin\n",
            "copying seaquest.bin from HC ROMS/BY ALPHABET/S-Z/Seaquest.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/seaquest.bin\n",
            "copying skiing.bin from HC ROMS/BY ALPHABET/S-Z/Skiing.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/skiing.bin\n",
            "copying solaris.bin from HC ROMS/BY ALPHABET/S-Z/Solaris.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/solaris.bin\n",
            "copying space_invaders.bin from HC ROMS/BY ALPHABET/S-Z/Space Invaders.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/space_invaders.bin\n",
            "copying surround.bin from HC ROMS/BY ALPHABET/S-Z/Surround - Chase.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/surround.bin\n",
            "copying tennis.bin from HC ROMS/BY ALPHABET/S-Z/Tennis.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tennis.bin\n",
            "copying trondead.bin from HC ROMS/BY ALPHABET/S-Z/TRON - Deadly Discs.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/trondead.bin\n",
            "copying tutankham.bin from HC ROMS/BY ALPHABET/S-Z/Tutankham.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/tutankham.bin\n",
            "copying venture.bin from HC ROMS/BY ALPHABET/S-Z/Venture.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/venture.bin\n",
            "copying pong.bin from HC ROMS/BY ALPHABET/S-Z/Video Olympics - Pong Sports.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/pong.bin\n",
            "copying video_pinball.bin from HC ROMS/BY ALPHABET/S-Z/Video Pinball - Arcade Pinball.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/video_pinball.bin\n",
            "copying wizard_of_wor.bin from HC ROMS/BY ALPHABET/S-Z/Wizard of Wor.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/wizard_of_wor.bin\n",
            "copying yars_revenge.bin from HC ROMS/BY ALPHABET/S-Z/Yars' Revenge.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/yars_revenge.bin\n",
            "copying zaxxon.bin from HC ROMS/BY ALPHABET/S-Z/Zaxxon.bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/zaxxon.bin\n",
            "copying assault.bin from HC ROMS/NTSC VERSIONS OF PAL ORIGINALS/Assault (AKA Sky Alien) (1983) (Bomb - Onbase) (CA281).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/assault.bin\n",
            "copying asterix.bin from ROMS/Asterix (AKA Taz) (07-27-1983) (Atari, Jerome Domurat, Steve Woita) (CX2696) (Prototype).bin to /usr/local/lib/python3.7/dist-packages/atari_py/atari_roms/asterix.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary packages \n",
        "import numpy as np\n",
        "import gym\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from scipy.misc import imresize\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n"
      ],
      "metadata": {
        "id": "D8W1XfoXzyV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "dtype = torch.float"
      ],
      "metadata": {
        "id": "e6NWaq-dhnEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we define an environment wrapper to handle the preprocessing of game frames\n",
        "# it works by cropping, resizing and changing the color scheme of the image \n",
        "# to make the process of training simpler and more efficient. \n",
        "class Atari_Wrapper(gym.Wrapper):\n",
        "    \n",
        "    def __init__(self, env, env_name, k, dsize=(84,84), use_add_done=False):\n",
        "      # cropping the game frames \n",
        "        super(Atari_Wrapper, self).__init__(env)\n",
        "        self.dsize = dsize\n",
        "        self.k = k\n",
        "        self.use_add_done = use_add_done\n",
        "        \n",
        "        self.frame_cutout_h = (31,-16)\n",
        "        self.frame_cutout_w = (7,-7)\n",
        "        \n",
        "    def reset(self):\n",
        "      # resetting the environment \n",
        "        self.Return = 0\n",
        "        self.last_life_count = 0\n",
        "        \n",
        "        ob = self.env.reset()\n",
        "        ob = self.preprocess_observation(ob)\n",
        "        \n",
        "        # stack the observations k times \n",
        "        # concatenating the state space as one input\n",
        "        self.frame_stack = np.stack([ob for i in range(self.k)])\n",
        "        \n",
        "        return self.frame_stack\n",
        "    \n",
        "    \n",
        "    def step(self, action): \n",
        "        # skipping k frames, for every intermediate frame and stacking these frames\n",
        "        reward = 0\n",
        "        done = False\n",
        "        additional_done = False\n",
        "        \n",
        "        # skip k frames or end the episode\n",
        "        frames = []\n",
        "        for i in range(self.k):\n",
        "            \n",
        "            ob, r, d, info = self.env.step(action)\n",
        "            \n",
        "            if self.use_add_done:\n",
        "              # the agent has lost the game, signify that the game is finished \n",
        "                if info['ale.lives'] < self.last_life_count:\n",
        "                    additional_done = True  \n",
        "              # otherwise update the live count\n",
        "                self.last_life_count = info['ale.lives']\n",
        "            \n",
        "            ob = self.preprocess_observation(ob)\n",
        "            frames.append(ob)\n",
        "            \n",
        "            # increment the reward by current r\n",
        "            reward += r\n",
        "            \n",
        "            # if the game is finished\n",
        "            if d: \n",
        "                done = True\n",
        "                break\n",
        "                       \n",
        "        # build the frame stack (observation stack)\n",
        "        self.step_frame_stack(frames)\n",
        "        \n",
        "        self.Return += reward\n",
        "        if done:\n",
        "            info[\"return\"] = self.Return\n",
        "            \n",
        "        # clip reward\n",
        "        if reward > 0:\n",
        "            reward = 1\n",
        "        elif reward == 0:\n",
        "            reward = 0\n",
        "        else:\n",
        "            reward = -1\n",
        "            \n",
        "        return self.frame_stack, reward, done, info, additional_done\n",
        "    \n",
        "    def step_frame_stack(self, frames):\n",
        "        \n",
        "        num_frames = len(frames)\n",
        "        \n",
        "        if num_frames == self.k:\n",
        "            self.frame_stack = np.stack(frames)\n",
        "        elif num_frames > self.k:\n",
        "            self.frame_stack = np.array(frames[-k::])\n",
        "            # in case that the episode is finished\n",
        "        else: \n",
        "            self.frame_stack[0: self.k - num_frames] = self.frame_stack[num_frames::]\n",
        "            self.frame_stack[self.k - num_frames::] = np.array(frames)  \n",
        "            # adding a new frame into the frame stack\n",
        "            \n",
        "    # resizing the image \n",
        "    def preprocess_observation(self, ob):\n",
        "    \n",
        "        ob = cv2.cvtColor(ob[self.frame_cutout_h[0]:self.frame_cutout_h[1],\n",
        "                           self.frame_cutout_w[0]:self.frame_cutout_w[1]], cv2.COLOR_BGR2GRAY)\n",
        "        ob = cv2.resize(ob, dsize=self.dsize)\n",
        "    \n",
        "        return ob"
      ],
      "metadata": {
        "id": "J9dF63JQz2K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DQN(nn.Module):\n",
        "    # let's build the model\n",
        "    # torch nn is the base class for all neural network modules \n",
        "    # therefore we are subclassing this class and reimplementing the important and necessary methods\n",
        "    \n",
        "    def __init__(self, in_channels, num_actions):\n",
        "      # constructor for our network that inputs the input channels and the number of actins\n",
        "      # in this case it's not necessary to strictly input the number of actons since we are only working on \n",
        "      # one game (breakout) \n",
        "      # however, this method can be reused for any other Atari game just by changing the number of actions as input\n",
        "      # since different atari games have a different. number of actions \n",
        "        super().__init__()\n",
        "      \n",
        "      # the network consists of three convolution2d layers\n",
        "      # it uses the ReLU activation function\n",
        "      # it also uses the flattening layer as well as linear transformation layers\n",
        "        network = [\n",
        "            torch.nn.Conv2d(in_channels, 32, kernel_size=8, stride=4, padding=0),\n",
        "            nn.ReLU(),\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
        "            nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64*7*7,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_actions)\n",
        "        ]\n",
        "        # the network is a sequential model\n",
        "        self.network = nn.Sequential(*network)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        actions = self.network(x)\n",
        "        return actions\n",
        "\n",
        "class Agent(nn.Module):\n",
        "    # agent to play the breakout game \n",
        "    def __init__(self, in_channels, num_actions, epsilon):\n",
        "      # again the number of actions only passed in in case we want to play a different game in the future\n",
        "      # it also inputs the input channels and the epsilon variable \n",
        "        super().__init__()\n",
        "        \n",
        "        self.in_channels = in_channels\n",
        "        self.num_actions = num_actions\n",
        "        # sets the network with the custom DQN network object we defined above  \n",
        "        self.network = DQN(in_channels, num_actions)\n",
        "        \n",
        "        self.eps = epsilon\n",
        "    \n",
        "    def forward(self, x):\n",
        "        actions = self.network(x)\n",
        "        return actions\n",
        "    \n",
        "    def e_greedy(self, x):\n",
        "        # epsilon greedy policy selection of actions\n",
        "        # we'll sometimes use the model to choose the action\n",
        "        # sometimes we will sample one uniformly\n",
        "        # pytorch provides specific functions to implement this policy\n",
        "        actions = self.forward(x)\n",
        "        \n",
        "        greedy = torch.rand(1)\n",
        "        if self.eps < greedy:\n",
        "            return torch.argmax(actions)\n",
        "        else:\n",
        "            return (torch.rand(1) * self.num_actions).type('torch.LongTensor')[0] \n",
        "        \n",
        "    def greedy(self, x):\n",
        "      # The greedy policy. \n",
        "      # the agent will constantly perform the action that is expected to return the highest reward\n",
        "        actions = self.forward(x)\n",
        "        return torch.argmax(actions)\n",
        "    \n",
        "    def set_epsilon(self, epsilon):\n",
        "      # set the epsilon parameter for the network, which will define the probability of using a random action\n",
        "      # when using the e_greedy policy approach to learning. \n",
        "        self.eps = epsilon"
      ],
      "metadata": {
        "id": "JZanQNsq0nct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Logger:\n",
        "    \n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "        \n",
        "        f = open(f\"{self.filename}.csv\", \"w\")\n",
        "        f.close()\n",
        "        \n",
        "    def log(self, msg):\n",
        "        f = open(f\"{self.filename}.csv\", \"a+\")\n",
        "        f.write(f\"{msg}\\n\")\n",
        "        f.close()\n",
        "\n",
        "class Experience_Replay():\n",
        "  # implementing the experience replay technique, which stores the necessary infomation about\n",
        "  # the network's performance at every step of the game process. \n",
        "  # the information stored are [STATE, ACTION, REWARD, NEXT STATE] a.k.a. sars\n",
        "  # this allows for a more efficient learning and better convergence behavior of the network\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def insert(self, transitions):\n",
        "        # store current transition in memory\n",
        "        for i in range(len(transitions)):\n",
        "            if len(self.memory) < self.capacity:\n",
        "                self.memory.append(None)\n",
        "            self.memory[self.position] = transitions[i]\n",
        "            self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def get(self, batch_size):\n",
        "        #return random.sample(self.memory, batch_size)\n",
        "        indexes = (np.random.rand(batch_size) * (len(self.memory)-1)).astype(int)\n",
        "        return [self.memory[i] for i in indexes]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "class Env_Runner:\n",
        "    \n",
        "    def __init__(self, env, agent):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        \n",
        "        self.logger = Logger(\"training_info\")\n",
        "        self.logger.log(\"training_step, return\")\n",
        "        \n",
        "        self.ob = self.env.reset()\n",
        "        self.total_steps = 0\n",
        "        \n",
        "    def run(self, steps):\n",
        "        \n",
        "        obs = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        dones = []\n",
        "        \n",
        "        for step in range(steps):\n",
        "            \n",
        "            self.ob = torch.tensor(self.ob) # uint8\n",
        "            action = self.agent.e_greedy(\n",
        "                self.ob.to(device).to(dtype).unsqueeze(0) / 255) # float32+norm\n",
        "            action = action.detach().cpu().numpy()\n",
        "            \n",
        "            obs.append(self.ob)\n",
        "            actions.append(action)\n",
        "            \n",
        "            self.ob, r, done, info, additional_done = self.env.step(action)\n",
        "               \n",
        "            if done: # real environment reset, other add_dones are for q learning purposes\n",
        "                self.ob = self.env.reset()\n",
        "                if \"return\" in info:\n",
        "                    self.logger.log(f'{self.total_steps+step},{info[\"return\"]}')\n",
        "            \n",
        "            rewards.append(r)\n",
        "            dones.append(done or additional_done)\n",
        "            \n",
        "        self.total_steps += steps\n",
        "                                    \n",
        "        return obs, actions, rewards, dones\n",
        "    \n",
        "def make_transitions(obs, actions, rewards, dones):\n",
        "    # observations are in uint8 format\n",
        "    \n",
        "    tuples = []\n",
        "\n",
        "    steps = len(obs) - 1\n",
        "    for t in range(steps):\n",
        "        tuples.append((obs[t],\n",
        "                       actions[t],\n",
        "                       rewards[t],\n",
        "                       obs[t+1],\n",
        "                       int(not dones[t])))\n",
        "        \n",
        "    return tuples"
      ],
      "metadata": {
        "id": "Hn3uxzyi0r9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_name = 'BreakoutNoFrameskip-v4'\n",
        "\n",
        "# defining the hyper parameters\n",
        "\n",
        "# 4 frames get stacked together, 4 is a number that's commonly used and performs better in most networks\n",
        "num_stacked_frames = 4 \n",
        "# defining the length of the memory that stores experience replay \n",
        "# a.k.a all the states that the network goes through as our agent plays breakout \n",
        "replay_memory_size = 250000\n",
        "min_replay_size_to_update = 25000 #replay buffer \n",
        "# min_replay_size_to_update = 250 #replay buffer \n",
        "\n",
        "# learning rate, from research 2.5e-5 seems to be most suited for breakout bash\n",
        "lr = 2.5e-5 \n",
        "\n",
        "# the discount factor for our DQN, quantifying how much importance we \n",
        "# give for future rewards\n",
        "gamma = 0.99\n",
        "\n",
        "# batch size \n",
        "minibatch_size = 32\n",
        "steps_rollout = 16\n",
        "\n",
        "start_eps = 1\n",
        "final_eps = 0.1\n",
        "final_eps_frame = 1000000\n",
        "total_steps = 20000000\n",
        "\n",
        "# the more steps we allow our agent to take, the better the performace might be.\n",
        "# however, we are constained by the abilities of our machines and of course, time. \n",
        "# total_steps = 1000\n",
        "\n",
        "target_net_update = 625 # 625 - 10000 steps\n",
        "# target_net_update = 62 # 625 - 10000 steps\n",
        "\n",
        "\n",
        "# save_model_steps = 500000\n",
        "save_model_steps = 50000\n",
        "\n",
        "# initialize our environment with the build in gym.make functionality\n",
        "raw_env = gym.make(env_name)\n",
        "\n",
        "# update the raw environment by passing it to the wrapper we made initially \n",
        "# the wrapper allows for preprocessing the game frames for easier training \n",
        "env = Atari_Wrapper(raw_env, env_name, num_stacked_frames, use_add_done=True)\n",
        "\n",
        "# number of input channels and actions in the game \n",
        "in_channels = num_stacked_frames\n",
        "num_actions = env.action_space.n\n",
        "\n",
        "# the interval between final and beginning epsilon score \n",
        "eps_interval = start_eps-final_eps\n",
        "\n",
        "# initializing the original agent\n",
        "agent = Agent(in_channels, num_actions, start_eps).to(device)\n",
        "\n",
        "# defining the target agent \n",
        "# the target network is a copy of our original network, and we use it for the s and a value updates \n",
        "target_agent = Agent(in_channels, num_actions, start_eps).to(device)\n",
        "target_agent.load_state_dict(agent.state_dict())\n",
        "\n",
        "replay = Experience_Replay(replay_memory_size)\n",
        "runner = Env_Runner(env, agent)\n",
        "\n",
        "# our optimizer is Adam because it generally performs the best \n",
        "optimizer = optim.Adam(agent.parameters(), lr=lr)\n",
        "huber_loss = torch.nn.SmoothL1Loss()\n",
        "\n",
        "num_steps = 0\n",
        "num_model_updates = 0\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "losses = [] \n",
        "\n",
        "while num_steps < total_steps:\n",
        "    # for each step in the game \n",
        "\n",
        "    # calculating the epsilon variable, setting the agent exploration to the new epsilon\n",
        "    new_epsilon = np.maximum(final_eps, start_eps - ( eps_interval * num_steps/final_eps_frame))\n",
        "    agent.set_epsilon(new_epsilon)\n",
        "    \n",
        "    # get the data at each step\n",
        "    obs, actions, rewards, dones = runner.run(steps_rollout)\n",
        "\n",
        "    # make transition is the method we defined earlier in the code\n",
        "    transitions = make_transitions(obs, actions, rewards, dones)\n",
        "    replay.insert(transitions)\n",
        "    \n",
        "    # update the number of steps \n",
        "    num_steps += steps_rollout\n",
        "    \n",
        "    # check if it's time to update\n",
        "    if num_steps < min_replay_size_to_update:\n",
        "        continue\n",
        "    \n",
        "    # if we have reached the point of updating, we update the observation, actions, rewards, next observbation\n",
        "    for update in range(4):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        minibatch = replay.get(minibatch_size)\n",
        "        \n",
        "        # cast to float and normalize to 0-1\n",
        "        obs = (torch.stack([i[0] for i in minibatch]).to(device).to(dtype)) / 255 \n",
        "        \n",
        "        actions = np.stack([i[1] for i in minibatch])\n",
        "        rewards = torch.tensor([i[2] for i in minibatch]).to(device)\n",
        "        \n",
        "        # cast to float and normalize to 0-1\n",
        "        next_obs = (torch.stack([i[3] for i in minibatch]).to(device).to(dtype)) / 255\n",
        "        \n",
        "        dones = torch.tensor([i[4] for i in minibatch]).to(device)\n",
        "        \n",
        "        # Q score\n",
        "        # calculating the predictions in this part \n",
        "        Qs = agent(torch.cat([obs, next_obs]))\n",
        "        obs_Q, next_obs_Q = torch.split(Qs, minibatch_size ,dim=0)\n",
        "        \n",
        "        obs_Q = obs_Q[range(minibatch_size), actions]\n",
        "        \n",
        "        # target Q score\n",
        "        next_obs_Q_max = torch.max(next_obs_Q,1)[1].detach()\n",
        "        target_Q = target_agent(next_obs)[range(minibatch_size), next_obs_Q_max].detach()\n",
        "        \n",
        "        target = rewards + gamma * target_Q * dones\n",
        "        \n",
        "        # calculating the loss function\n",
        "        # huber loss is a loss function for robust regression which is not \n",
        "        # very sensitive to outliers, therefore works well with DQNs \n",
        "        loss = huber_loss(obs_Q, target) \n",
        "        losses.append(loss) \n",
        "        # torch.mean(torch.pow(obs_Q - target, 2))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    num_model_updates += 1\n",
        "     \n",
        "    # updating the target network\n",
        "    if num_model_updates%target_net_update == 0:\n",
        "        target_agent.load_state_dict(agent.state_dict())\n",
        "    \n",
        "    # print time\n",
        "    if num_steps%50000 < steps_rollout:\n",
        "        end_time = time.time()\n",
        "        print(f'*** total steps: {num_steps} | time(50K): {end_time - start_time} ***')\n",
        "        start_time = time.time()\n",
        "    \n",
        "    # save the dqn after some time\n",
        "    if num_steps%save_model_steps < steps_rollout:\n",
        "        torch.save(agent,f\"{env_name}-{num_steps}.pt\")\n",
        "\n",
        "env.close()"
      ],
      "metadata": {
        "id": "MunsWFmH0vcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "id": "G5e_bYhx4C4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# beginning to set up the display for the game\n",
        "# we let the agent play breakout and display it's performace at every frame\n",
        "# this allows to evaluate the performance in real time, as well as it being entertaining \n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUTjW2cG4Hov",
        "outputId": "3b23bac9-b07e-4d4f-a52c-ddb28e192397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f28277d87d0>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving and loading the agent we optimized in the previous steps\n",
        "torch.save(agent,\"agent.pt\")\n",
        "agent = torch.load(\"agent.pt\")\n",
        "\n",
        "# reimporting the environment and rewrapping it with our custom class\n",
        "# to again, preprocess the game frames for easier interaction\n",
        "raw_env = gym.make(env_name)\n",
        "env = Atari_Wrapper(raw_env, env_name, num_stacked_frames)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "# the number of steps again, determine how well our agent might play the game\n",
        "# however - it is constrained by machine abilities and time. \n",
        "steps = 5000\n",
        "# steps = 1000\n",
        "agent.set_epsilon(0.025)\n",
        "\n",
        "# evaluating the agent, this displays the structure of the network \n",
        "agent.eval()\n",
        "\n",
        "# rendering the screen, the game will be displayed in RGB, despite being trained in grayscale\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "\n",
        "# plt allows us to display the game play on the screen\n",
        "# all we are doing is plotting each frame of the game at a time\n",
        "plt.imshow(prev_screen)\n",
        "rewards = []\n",
        "\n",
        "cur_reward = 0\n",
        "cumulative_rewards = [] \n",
        "\n",
        "for i in range(steps):\n",
        "  # for every step in the game we are using the epsilon greedy policy to update the \n",
        "  # action that the agent is going to take, passing in the observation from previous go\n",
        "  action = agent.e_greedy(torch.tensor(obs, dtype=dtype).unsqueeze(0).to(device) / 255)\n",
        "  action = action.detach().cpu().numpy()\n",
        "\n",
        "  # loading the information from the current step\n",
        "  obs, reward, done, info, _ = env.step(action)\n",
        "  rewards.append(reward)\n",
        "\n",
        "  cur_reward += reward\n",
        "  cumulative_rewards.append(cur_reward) \n",
        "\n",
        "  # rerendering the screen to get it ready to display the next state in the game \n",
        "  screen = env.render(mode='rgb_array')\n",
        "  \n",
        "  plt.imshow(screen)\n",
        "  ipythondisplay.clear_output(wait=True)\n",
        "  ipythondisplay.display(plt.gcf())\n",
        "\n",
        "  # in case we are done with the game (lost or won) we simply end plotting game frames \n",
        "  if done:\n",
        "    obs = env.reset()\n",
        "    print(info)\n",
        "    break\n",
        "\n",
        "ipythondisplay.clear_output(wait=True)\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "PALss2YC3MDY",
        "outputId": "813bb268-d8ad-4cb3-f7d5-ca1e896feade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent.eval())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJlTYVKv6joR",
        "outputId": "b324ae2e-a99d-4305-e868-f7a56a929741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent(\n",
            "  (network): DQN(\n",
            "    (network): Sequential(\n",
            "      (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "      (1): ReLU()\n",
            "      (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "      (3): ReLU()\n",
            "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (5): ReLU()\n",
            "      (6): Flatten(start_dim=1, end_dim=-1)\n",
            "      (7): Linear(in_features=3136, out_features=512, bias=True)\n",
            "      (8): ReLU()\n",
            "      (9): Linear(in_features=512, out_features=4, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.unwrapped.get_action_meanings())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXXjc19_8Us6",
        "outputId": "1af29193-d7a2-4f99-fd57-a0054bc7645b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.observation_space.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBrggxwZ_S4v",
        "outputId": "9951427d-32fa-4972-aba3-a8d7df25d33a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 160, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(losses)"
      ],
      "metadata": {
        "id": "zfb90P0HArP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3278d559-271f-41de-8c0d-7fa15ad73655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.9841e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.9343e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.5916e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.8479e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.0378e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.1423e-07, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0012, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0012, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0011, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0010, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0153, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0153, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0008, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0152, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.7222e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.1394e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.9169e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.0384e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.0492e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.1132e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.9177e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.2635e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.6693e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.2068e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.4169e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.9926e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.3858e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.7137e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.7617e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.9739e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.1382e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.6127e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.2981e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.8686e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.1269e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.1497e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.6770e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.3912e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.5011e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.3851e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.7060e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.2999e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.3470e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.4599e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.9373e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.8772e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.0388e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.3768e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.7124e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.1899e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.1341e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.5974e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.8051e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.5712e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.9163e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.2776e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.2203e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.0065e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.1185e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.8897e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.0707e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.2185e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.8836e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.3015e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.1204e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.6204e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.2455e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.0660e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.0213e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.3401e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.6500e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.8482e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.2837e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.2020e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.2799e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0153, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.9789e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.7552e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.8053e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.6970e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.4771e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.0388e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.1752e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.8019e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.5029e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.2192e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.8569e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.5054e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.8198e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.8827e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.4778e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0304, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.2279e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.3573e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.5082e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.7933e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.6182e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0298, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.8770e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.5764e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0151, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.0876e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0150, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.4143e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0149, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.9970e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.5144e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0160, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0153, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0148, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0148, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0146, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0170, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0329, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0166, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.0144e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0151, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0010, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0308, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.9779e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.2698e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.0101e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.5316e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.0661e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.5865e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0159, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.4378e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.1704e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.1520e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.5091e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0311, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0151, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.2737e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.2121e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.8985e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.1148e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.9195e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.5642e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.9604e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.6120e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.8507e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.4507e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.6897e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0160, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.9290e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0159, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0162, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0159, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.7910e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0298, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0443, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0155, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0166, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0324, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0152, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0162, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0010, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0010, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0015, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0014, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.9725e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0160, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.7429e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0319, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.4695e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.4345e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0008, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.5925e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.7198e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.0356e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.4505e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0004, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0302, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0005, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0151, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0011, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0022, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0009, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0164, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0164, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0314, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0020, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0162, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.2147e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.5608e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0152, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.1345e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.6246e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0315, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0156, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0160, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0003, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0010, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0166, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0018, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0151, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0015, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0008, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.4831e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.1735e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0012, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.3057e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.1658e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.6082e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0158, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0177, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.2097e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.4025e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.5041e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0154, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.5052e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.6258e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.8809e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0012, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.8983e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.4021e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0012, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.5989e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.9507e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0162, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0164, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(8.3782e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.4884e-06, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0162, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(4.5732e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.3744e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.0445e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0014, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.5755e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.0074e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.1949e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0007, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.7859e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0168, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.9320e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.3765e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0019, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(3.0100e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0006, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.0127e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(1.3539e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(2.1827e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0021, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0157, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0008, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0167, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(7.5717e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(5.5465e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(9.2932e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0013, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0008, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0026, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(6.8017e-05, device='cuda:0', grad_fn=<SmoothL1LossBackward0>), 1, tensor(0.0001, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cumulative_rewards)"
      ],
      "metadata": {
        "id": "OTmCh4GlwTGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rewards)"
      ],
      "metadata": {
        "id": "PtDBnqa_5Ijd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cumulative_rewards)"
      ],
      "metadata": {
        "id": "J2Rv45-c5Mub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses[5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SU7p9kYg72VO",
        "outputId": "116c696f-9eb0-4ebf-bf6f-4bbecff066c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0002, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses[0].item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKUHsz88Gg6",
        "outputId": "eed86c02-dbb1-4597-a447-328e24aa31d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016777437180280685"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values = []\n",
        "for loss in losses: \n",
        "  loss_values.append(loss.item())"
      ],
      "metadata": {
        "id": "89mTek3p8kqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2md9pTD8tHl",
        "outputId": "bcfe930a-a7ab-4642-f294-a72dde5bfd79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.016777437180280685,\n",
              " 0.00015276367776095867,\n",
              " 0.01638644002377987,\n",
              " 0.01615068130195141,\n",
              " 0.00010679624392651021,\n",
              " 5.556775431614369e-05,\n",
              " 7.452061981894076e-05,\n",
              " 0.00036233363789506257,\n",
              " 0.00027746689738705754,\n",
              " 0.000308906746795401,\n",
              " 0.0003543088096193969,\n",
              " 0.014855608344078064,\n",
              " 0.014759424142539501,\n",
              " 0.014636578038334846,\n",
              " 0.0004784221819136292,\n",
              " 0.00037318700924515724,\n",
              " 0.0002505072043277323,\n",
              " 0.0003611947176977992,\n",
              " 0.00022111526050139219,\n",
              " 0.0003529264940880239,\n",
              " 0.00011338792683091015,\n",
              " 0.000334239739459008,\n",
              " 0.00016480374324601144,\n",
              " 0.0003768049937207252,\n",
              " 0.00034054997377097607,\n",
              " 0.00035419478081166744,\n",
              " 0.00041761796455830336,\n",
              " 0.00031481427140533924,\n",
              " 0.00038501425296999514,\n",
              " 0.00037837226409465075,\n",
              " 0.0003719939268194139,\n",
              " 0.0003617950715124607,\n",
              " 0.0002503940195310861,\n",
              " 0.0002504297881387174,\n",
              " 0.00023690321540925652,\n",
              " 0.0002292544668307528,\n",
              " 0.00019214948406443,\n",
              " 0.00014878828369546682,\n",
              " 0.00018576579168438911,\n",
              " 0.0001321779127465561,\n",
              " 0.03191746771335602,\n",
              " 0.00010701718565542251,\n",
              " 0.00010118974023498595,\n",
              " 7.051773718558252e-05,\n",
              " 5.669762322213501e-05,\n",
              " 5.4954121878836304e-05,\n",
              " 4.490490391617641e-05,\n",
              " 4.182299744570628e-05,\n",
              " 3.403370646992698e-05,\n",
              " 4.297976920497604e-05,\n",
              " 3.3852935303002596e-05,\n",
              " 3.462014501565136e-05,\n",
              " 1.3580312952399254e-05,\n",
              " 2.5848426957963966e-05,\n",
              " 1.0707060937420465e-05,\n",
              " 0.01548693049699068,\n",
              " 1.8884513337980025e-05,\n",
              " 2.218637746409513e-05,\n",
              " 1.925787000800483e-05,\n",
              " 4.0193153836298734e-05,\n",
              " 1.1353730769769754e-05,\n",
              " 3.964909410569817e-05,\n",
              " 5.3733267122879624e-05,\n",
              " 4.082856321474537e-05,\n",
              " 8.52276716614142e-05,\n",
              " 5.333744775271043e-05,\n",
              " 1.675362727837637e-05,\n",
              " 4.206411904306151e-05,\n",
              " 0.015613812021911144,\n",
              " 2.6766689188661985e-05,\n",
              " 1.2553062333608977e-05,\n",
              " 3.959253808716312e-05,\n",
              " 2.709897125896532e-05,\n",
              " 5.970342499495018e-06,\n",
              " 2.8855624805146363e-06,\n",
              " 6.20320497546345e-05,\n",
              " 5.5398453696398064e-05,\n",
              " 1.8068547433358617e-05,\n",
              " 1.9839988453895785e-05,\n",
              " 0.015649989247322083,\n",
              " 0.015608996152877808,\n",
              " 2.1169644242036156e-05,\n",
              " 5.0645667215576395e-05,\n",
              " 7.186669336078921e-06,\n",
              " 3.1505434890277684e-05,\n",
              " 2.724184923863504e-05,\n",
              " 0.015541307628154755,\n",
              " 4.692812217399478e-05,\n",
              " 6.032044257153757e-05,\n",
              " 4.268064731149934e-05,\n",
              " 6.994986324571073e-05,\n",
              " 0.015332769602537155,\n",
              " 5.4028452723287046e-05,\n",
              " 0.015725785866379738,\n",
              " 4.038935003336519e-05,\n",
              " 2.620756276883185e-05,\n",
              " 5.365319884731434e-05,\n",
              " 9.884896280709654e-05,\n",
              " 0.00012085428897989914,\n",
              " 4.27813756687101e-05,\n",
              " 5.701288318959996e-05,\n",
              " 6.342111737467349e-05,\n",
              " 7.807654037605971e-05,\n",
              " 1.7801305148168467e-05,\n",
              " 1.4384139831236098e-05,\n",
              " 1.170175619336078e-05,\n",
              " 8.481847180519253e-05,\n",
              " 8.316802268382162e-05,\n",
              " 0.015725333243608475,\n",
              " 4.3312800698913634e-05,\n",
              " 5.063809294370003e-05,\n",
              " 0.015657149255275726,\n",
              " 0.00020550884073600173,\n",
              " 9.203782246913761e-05,\n",
              " 9.451444930164143e-05,\n",
              " 0.00012580803013406694,\n",
              " 0.00015074873226694763,\n",
              " 0.00010313751408830285,\n",
              " 0.00012357620289549232,\n",
              " 0.00011736051237676293,\n",
              " 0.015731897205114365,\n",
              " 0.03147914260625839,\n",
              " 5.229399903328158e-05,\n",
              " 9.06808563740924e-05,\n",
              " 1.384403367410414e-05,\n",
              " 0.030620381236076355,\n",
              " 1.4000478586240206e-05,\n",
              " 0.01576983742415905,\n",
              " 0.00016916981257963926,\n",
              " 0.00016375449195038527,\n",
              " 6.438305717892945e-05,\n",
              " 9.106665675062686e-05,\n",
              " 0.0001452477736165747,\n",
              " 7.658837421331555e-05,\n",
              " 0.00023528086603619158,\n",
              " 6.543335621245205e-05,\n",
              " 0.0001436419115634635,\n",
              " 0.015594311989843845,\n",
              " 0.015975505113601685,\n",
              " 6.698557990603149e-05,\n",
              " 7.891561836004257e-05,\n",
              " 0.0001119851294788532,\n",
              " 7.172164623625576e-05,\n",
              " 6.043109533493407e-05,\n",
              " 0.00011591413203859702,\n",
              " 7.690764323342592e-05,\n",
              " 0.00012533710105344653,\n",
              " 6.291914178291336e-05,\n",
              " 0.00016664060240145773,\n",
              " 0.00011156549589941278,\n",
              " 0.00013059881166554987,\n",
              " 7.22869299352169e-05,\n",
              " 1.0267325706081465e-05,\n",
              " 6.919942825334147e-05,\n",
              " 5.499214239534922e-05,\n",
              " 0.00013040816702414304,\n",
              " 5.421155947260559e-06,\n",
              " 8.32205405458808e-05,\n",
              " 3.391738573554903e-05,\n",
              " 9.509254596196115e-05,\n",
              " 9.027207852341235e-05,\n",
              " 8.800254727248102e-05,\n",
              " 8.117649122141302e-05,\n",
              " 2.4273009330499917e-05,\n",
              " 0.015427796170115471,\n",
              " 1.6770736692706123e-05,\n",
              " 0.00011304864892736077,\n",
              " 5.819058424094692e-05,\n",
              " 0.00010031372949015349,\n",
              " 7.238183752633631e-05,\n",
              " 6.765079888282344e-05,\n",
              " 1.5423478544107638e-05,\n",
              " 6.108110392233357e-05,\n",
              " 2.222700641141273e-05,\n",
              " 1.4169703717925586e-05,\n",
              " 6.082604522816837e-05,\n",
              " 0.0001971494930330664,\n",
              " 0.00010711755021475255,\n",
              " 0.0001069749632733874,\n",
              " 0.00016713800141587853,\n",
              " 1.1764235750888474e-05,\n",
              " 5.7685287174535915e-05,\n",
              " 0.015641404315829277,\n",
              " 1.1379712304915302e-05,\n",
              " 5.6254633818753064e-05,\n",
              " 6.565822695847601e-05,\n",
              " 0.00016341284208465368,\n",
              " 1.1561452083697077e-05,\n",
              " 0.00014263091725297272,\n",
              " 5.938521644566208e-05,\n",
              " 1.5108398656593636e-05,\n",
              " 6.113407289376482e-05,\n",
              " 0.00024064560420811176,\n",
              " 3.817688411800191e-05,\n",
              " 3.014438880200032e-05,\n",
              " 2.64290974882897e-05,\n",
              " 0.00010333150567021221,\n",
              " 9.617269824957475e-05,\n",
              " 0.00013464053336065263,\n",
              " 1.3755554391536862e-05,\n",
              " 0.0001528563443571329,\n",
              " 1.0207653758698143e-05,\n",
              " 7.437065505655482e-05,\n",
              " 7.86852469900623e-05,\n",
              " 1.8650953279575333e-05,\n",
              " 4.0593065932625905e-05,\n",
              " 0.015480642206966877,\n",
              " 0.0001080033034668304,\n",
              " 3.780201586778276e-05,\n",
              " 4.4180513214087114e-05,\n",
              " 3.550149631337263e-05,\n",
              " 3.655250839074142e-05,\n",
              " 0.0001841886987676844,\n",
              " 3.133022255497053e-05,\n",
              " 9.756765211932361e-05,\n",
              " 8.386739500565454e-05,\n",
              " 0.00013908807886764407,\n",
              " 1.1463579539849889e-05,\n",
              " 0.015862761065363884,\n",
              " 1.3259485058370046e-05,\n",
              " 1.6197445802390575e-05,\n",
              " 7.48277670936659e-05,\n",
              " 4.1586317820474505e-06,\n",
              " 4.392602932057343e-06,\n",
              " 5.75043486605864e-06,\n",
              " 0.01563417725265026,\n",
              " 0.00014488260785583407,\n",
              " 9.114420390687883e-05,\n",
              " 0.0002070869377348572,\n",
              " 1.0255318557028659e-05,\n",
              " 7.470600394299254e-05,\n",
              " 0.015636108815670013,\n",
              " 7.857147284084931e-05,\n",
              " 0.031072771176695824,\n",
              " 0.0001683673181105405,\n",
              " 3.066200588364154e-05,\n",
              " 0.0001871804124675691,\n",
              " 0.0001362061593681574,\n",
              " 0.015525593422353268,\n",
              " 0.0001242916623596102,\n",
              " 0.0001438763429177925,\n",
              " 0.03154068812727928,\n",
              " 5.333868466550484e-05,\n",
              " 4.9881855375133455e-05,\n",
              " 0.00013730561477132142,\n",
              " 2.900334948208183e-05,\n",
              " 0.00027095660334452987,\n",
              " 4.3103511416120455e-05,\n",
              " 4.030625495943241e-05,\n",
              " 0.015577398240566254,\n",
              " 0.015453287400305271,\n",
              " 0.015227901749312878,\n",
              " 7.057953189359978e-05,\n",
              " 8.234093547798693e-05,\n",
              " 0.00019322230946272612,\n",
              " 0.00020466822024900466,\n",
              " 0.015712475404143333,\n",
              " 0.015015022829174995,\n",
              " 0.015612092800438404,\n",
              " 0.00019844486087094992,\n",
              " 0.00027562404284253716,\n",
              " 0.000297907943604514,\n",
              " 0.00022758009436074644,\n",
              " 0.00023687987413723022,\n",
              " 0.016346978023648262,\n",
              " 0.0003820593119598925,\n",
              " 0.00021224851661827415,\n",
              " 0.000255837629083544,\n",
              " 0.0002044504217337817,\n",
              " 0.00032724643824622035,\n",
              " 0.0003014873946085572,\n",
              " 0.015389939770102501,\n",
              " 0.03144790604710579,\n",
              " 0.000354823365341872,\n",
              " 0.0003520716563798487,\n",
              " 0.0003002944868057966,\n",
              " 0.0003064451739192009,\n",
              " 0.00023193444940261543,\n",
              " 0.0013094329042360187,\n",
              " 0.015475178137421608,\n",
              " 0.0006335892248898745,\n",
              " 0.0007790920790284872,\n",
              " 0.0008682459010742605,\n",
              " 0.0008775898022577167,\n",
              " 0.0003244307590648532,\n",
              " 0.00047376356087625027,\n",
              " 0.00030794995836913586,\n",
              " 6.489806401077658e-05,\n",
              " 0.00048504775622859597,\n",
              " 6.775495421607047e-05,\n",
              " 0.016551891341805458,\n",
              " 0.00010724678577389568,\n",
              " 0.00031659845262765884,\n",
              " 0.00020960182882845402,\n",
              " 0.0003809484769590199,\n",
              " 0.00020646979101002216,\n",
              " 0.00020127215248066932,\n",
              " 0.0002075033262372017,\n",
              " 1.778119258233346e-05,\n",
              " 0.01584303379058838,\n",
              " 0.00012034692917950451,\n",
              " 0.00032965204445645213,\n",
              " 0.0002103102015098557,\n",
              " 0.00013672435306943953,\n",
              " 0.0001247522741323337,\n",
              " 5.524851803784259e-05,\n",
              " 0.00012213137233629823,\n",
              " 0.0001038738846546039,\n",
              " 0.031086836010217667,\n",
              " 0.015634993091225624,\n",
              " 0.000211509526707232,\n",
              " 2.554884849814698e-05,\n",
              " 8.181732482626103e-06,\n",
              " 4.793978405359667e-06,\n",
              " 0.00011385659308871254,\n",
              " 0.00011461685062386096,\n",
              " 1.5543207609880483e-06,\n",
              " 0.0003205933899153024,\n",
              " 0.00011756681487895548,\n",
              " 0.00022086837270762771,\n",
              " 0.000231032696319744,\n",
              " 0.00021617146558128297,\n",
              " 0.00019599235383793712,\n",
              " 0.00011602206359384581,\n",
              " 0.00011295538570266217,\n",
              " 0.00010829744132934138,\n",
              " 6.064296940166969e-06,\n",
              " 0.00031143854721449316,\n",
              " 0.01603182964026928,\n",
              " 0.015897829085588455,\n",
              " 1.535004003017093e-06,\n",
              " 9.893115930026397e-05,\n",
              " 6.564434897882165e-06,\n",
              " 0.00021240601199679077,\n",
              " 0.00022518157493323088,\n",
              " 6.07655783824157e-06,\n",
              " 0.0001276319526368752,\n",
              " 0.01568414643406868,\n",
              " 0.00011085948790423572,\n",
              " 0.00011646931670838967,\n",
              " 1.2197018804727122e-05,\n",
              " 2.667494845809415e-05,\n",
              " 2.0290492102503777e-05,\n",
              " 0.01575998030602932,\n",
              " 0.00012943097681272775,\n",
              " 4.0393184463027865e-05,\n",
              " 3.162756911478937e-05,\n",
              " 0.00034072392736561596,\n",
              " 0.00024417246459051967,\n",
              " 2.5800371076911688e-05,\n",
              " 0.000131432490888983,\n",
              " 0.0001773018593667075,\n",
              " 0.0001290651416638866,\n",
              " 0.00016398628940805793,\n",
              " 0.03146788850426674,\n",
              " 0.00018246236140839756,\n",
              " 0.00016677682287991047,\n",
              " 0.00017760382615961134,\n",
              " 0.00028804788598790765,\n",
              " 3.902117896359414e-05,\n",
              " 0.015934588387608528,\n",
              " 3.781911118494463e-06,\n",
              " 0.01593947596848011,\n",
              " 3.861442564812023e-06,\n",
              " 0.00014424276014324278,\n",
              " 6.685982498311205e-06,\n",
              " 9.433482773602009e-06,\n",
              " 1.4193798961059656e-05,\n",
              " 0.00016770949878264219,\n",
              " 0.0002582100860308856,\n",
              " 0.00012033884559059516,\n",
              " 1.804962448659353e-05,\n",
              " 1.4257811017159838e-05,\n",
              " 0.00025180523516610265,\n",
              " 2.0104782379348762e-05,\n",
              " 0.00012567895464599133,\n",
              " 0.015659911558032036,\n",
              " 1.816778240026906e-05,\n",
              " 0.015671102330088615,\n",
              " 0.00013271190982777625,\n",
              " 2.0436898921616375e-05,\n",
              " 2.796292392304167e-05,\n",
              " 0.00019068615802098066,\n",
              " 0.015639588236808777,\n",
              " 4.6545115765184164e-05,\n",
              " 0.00016666887677274644,\n",
              " 0.00014926734729669988,\n",
              " 0.01612699404358864,\n",
              " 0.0002747434191405773,\n",
              " 0.015499837696552277,\n",
              " 0.016085563227534294,\n",
              " 0.0004520731745287776,\n",
              " 2.7271224098512903e-05,\n",
              " 0.0005247638328000903,\n",
              " 0.0002414393238723278,\n",
              " 0.00020443258108571172,\n",
              " 0.000930021982640028,\n",
              " 5.6120221415767446e-05,\n",
              " 0.0003520385653246194,\n",
              " 0.01591075025498867,\n",
              " 0.00024321947421412915,\n",
              " 0.00048557319678366184,\n",
              " 0.00018510405789129436,\n",
              " 1.9529619748936966e-05,\n",
              " 2.097475044138264e-05,\n",
              " 1.5004639863036573e-05,\n",
              " 1.2779703865817282e-05,\n",
              " 8.089665243460331e-06,\n",
              " 0.0006214569439180195,\n",
              " 0.00018119753804057837,\n",
              " 0.0004446582170203328,\n",
              " 0.00015868702030275017,\n",
              " 0.0004393908893689513,\n",
              " 0.0004406066727824509,\n",
              " 1.6352496459148824e-05,\n",
              " 0.01598198339343071,\n",
              " 0.00015336739306803793,\n",
              " 0.0002944716834463179,\n",
              " 4.9690279411152005e-06,\n",
              " 0.01571590080857277,\n",
              " 0.00029869028367102146,\n",
              " 0.00015282501408364624,\n",
              " 0.015607091598212719,\n",
              " 0.00016347791824955493,\n",
              " 0.0001665968302404508,\n",
              " 0.01571395993232727,\n",
              " 0.0004593897610902786,\n",
              " 0.016041917726397514,\n",
              " 0.00016917097673285753,\n",
              " 0.00017711319378577173,\n",
              " 3.7245292332954705e-05,\n",
              " 2.250665784231387e-05,\n",
              " 0.0002864466514438391,\n",
              " 0.016391221433877945,\n",
              " 0.0004109068831894547,\n",
              " 6.48813002044335e-05,\n",
              " 4.803783667739481e-05,\n",
              " 0.0004672913928516209,\n",
              " 0.016206728294491768,\n",
              " 0.0002159337600460276]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(loss_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "LpkA3kyW8uE5",
        "outputId": "b7afc97d-be09-4ea7-e069-1bcd61a78447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f282833c310>]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-2ACcvE2-aqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}